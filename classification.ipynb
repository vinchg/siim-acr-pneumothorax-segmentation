{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as pd\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pydicom\n",
    "import scipy\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from matplotlib import pyplot as plt\n",
    "from utils.mask_functions import *\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnext import ResNeXt50\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, LeakyReLU, core, Dropout, BatchNormalization, Concatenate, Dense, Flatten, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Data - Create Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = './siim/dicom-images-train/*/*/*.dcm'\n",
    "mask_path = './siim/train-rle.csv'\n",
    "images_to_ram = False\n",
    "img_height = 512\n",
    "img_width = 512\n",
    "n_channels = 1\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_df(train_path=train_path, mask_path=mask_path, images_to_ram=False):\n",
    "    rles_df = pd.read_csv(mask_path)\n",
    "    rles_df.columns = ['ImageId', 'EncodedPixels']\n",
    "    rles_df['Pneumothorax'] = 0\n",
    "    rles_df['NotPneumothorax'] = 0\n",
    "    rles_df['FilePath'] = ''\n",
    "    if images_to_ram is True:\n",
    "        rles_df['PixelArray'] = []\n",
    "        \n",
    "    for n in range(len(rles_df)):\n",
    "        if '-1' not in rles_df.loc[n, 'EncodedPixels']:\n",
    "            rles_df.loc[n, 'Pneumothorax'] = 1\n",
    "        else:\n",
    "            rles_df.loc[n, 'NotPneumothorax'] = 1\n",
    "        \n",
    "    # Add file path to dataframe\n",
    "    train_fps = glob(train_path)\n",
    "    for fp in train_fps:\n",
    "        dcm = pydicom.dcmread(fp)\n",
    "        rles_df.loc[rles_df.ImageId == dcm.SOPInstanceUID, 'FilePath'] = fp\n",
    "        if images_to_ram is True:\n",
    "            rles_df.loc[rles_df.ImageId == dcm.SOPInstanceUID, 'PixelArray'] = dcm.pixel_array\n",
    "            \n",
    "    return rles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>NotPneumothorax</th>\n",
       "      <th>FilePath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.5597.151787518...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>./siim/dicom-images-train\\1.2.276.0.7230010.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.12515.15178752...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>./siim/dicom-images-train\\1.2.276.0.7230010.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.4904.151787518...</td>\n",
       "      <td>175349 7 1013 12 1009 17 1005 19 1003 20 1002...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>./siim/dicom-images-train\\1.2.276.0.7230010.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.32579.15178751...</td>\n",
       "      <td>407576 2 1021 7 1015 10 1013 12 1011 14 1008 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>./siim/dicom-images-train\\1.2.276.0.7230010.3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.32579.15178751...</td>\n",
       "      <td>252069 1 1021 3 1020 4 1018 5 1018 6 1016 7 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>./siim/dicom-images-train\\1.2.276.0.7230010.3....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  \\\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.5597.151787518...   \n",
       "1  1.2.276.0.7230010.3.1.4.8323329.12515.15178752...   \n",
       "2  1.2.276.0.7230010.3.1.4.8323329.4904.151787518...   \n",
       "3  1.2.276.0.7230010.3.1.4.8323329.32579.15178751...   \n",
       "4  1.2.276.0.7230010.3.1.4.8323329.32579.15178751...   \n",
       "\n",
       "                                       EncodedPixels  Pneumothorax  \\\n",
       "0                                                 -1             0   \n",
       "1                                                 -1             0   \n",
       "2   175349 7 1013 12 1009 17 1005 19 1003 20 1002...             1   \n",
       "3   407576 2 1021 7 1015 10 1013 12 1011 14 1008 ...             1   \n",
       "4   252069 1 1021 3 1020 4 1018 5 1018 6 1016 7 1...             1   \n",
       "\n",
       "   NotPneumothorax                                           FilePath  \n",
       "0                1  ./siim/dicom-images-train\\1.2.276.0.7230010.3....  \n",
       "1                1  ./siim/dicom-images-train\\1.2.276.0.7230010.3....  \n",
       "2                0  ./siim/dicom-images-train\\1.2.276.0.7230010.3....  \n",
       "3                0  ./siim/dicom-images-train\\1.2.276.0.7230010.3....  \n",
       "4                0  ./siim/dicom-images-train\\1.2.276.0.7230010.3....  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_train_df(train_path, mask_path, images_to_ram)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Balance the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3286, 8296)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imbalance between Pos and Neg classifications:\n",
    "#len(rles_df[rles_df.Pneumothorax == 1]), len(rles_df[rles_df.Pneumothorax == 0])\n",
    "len(df[df.Pneumothorax == 1]), len(df[df.Pneumothorax == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_df, val_df = train_test_split(rles_df, stratify=rles_df.Pneumothorax, test_size=0.2, random_state=88)\n",
    "train_df, val_df = train_test_split(df, stratify=df.Pneumothorax, test_size=0.2, random_state=88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img_height = 1024\n",
    "img_width = 1024\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, data_frame,\n",
    "                 batch_size=4,\n",
    "                 augmentations=None,\n",
    "                 img_height=512,\n",
    "                 img_width=512,\n",
    "                 n_channels=1,\n",
    "                 shuffle=True):\n",
    "        self.data_frame = data_frame\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        #self.indexes = np.arange(len(self.data_frame))\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Batches per epoch'\n",
    "        return int(np.ceil(len(self.data_frame) / self.batch_size))\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Update indexes when epoch ends'\n",
    "        self.indexes = np.arange(len(self.data_frame))\n",
    "        if self.shuffle == True:\n",
    "            #self.indexes = np.arange(len(self.data_frame))\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        'Get one batch'\n",
    "        batch_indexes = self.indexes[index*self.batch_size:min((index+1)*self.batch_size,len(self.data_frame))]\n",
    "        \n",
    "        #fps = self.data_frame.iloc[batch_indexes].FilePath\n",
    "        \n",
    "        #X = self.data_generation(fps)\n",
    "        #Y = self.data_frame.iloc[batch_indexes][['Pneumothorax', 'NotPneumothorax']]\n",
    "        X, Y = self.data_Generation(batch_indexes)\n",
    "        \n",
    "        if self.augment is None:\n",
    "            return np.array(X)/255, np.array(Y)\n",
    "        else:\n",
    "            X_aug, Y_aug = [], []\n",
    "            for image, mask in zip(X, Y):\n",
    "                augmented = self.augment(image=image, mask=mask)\n",
    "                X_aug.append(augmented['image'])\n",
    "                Y_aug.append(augmented['mask'])\n",
    "            return np.array(X_aug)/255, np.array(Y_aug)\n",
    "        \n",
    "    #def data_generation(self, fps):\n",
    "    def data_generation(self, batch_indexes):\n",
    "        # Check if image data is in df, otherwise load them from filepaths\n",
    "        if 'PixelArray' in df.columns:\n",
    "            # CHECK THIs LINE\n",
    "            X = cv2.resize(self.data_frame.iloc[batch_indexes]['PixelArray'], (self.img_height, self.img_width)), axis=2)\n",
    "        else:   \n",
    "            fps = self.data_frame.iloc[batch_indexes].FilePath\n",
    "            X = np.empty((len(fps), self.img_height, self.img_width, self.n_channels))\n",
    "            for i, fp in enumerate(fps):\n",
    "                dcm = pydicom.dcmread(fp)\n",
    "                X[i] = np.expand_dims(cv2.resize(dcm.pixel_array, (self.img_height, self.img_width)), axis=2)\n",
    "            \n",
    "        Y = self.data_frame.iloc[batch_indexes][['Pneumothorax', 'NotPneumothorax']]\n",
    "        \n",
    "        return np.uint8(X), np.uint(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, HorizontalFlip, CLAHE, HueSaturationValue,\n",
    "    RandomBrightness, RandomContrast, RandomGamma,OneOf,\n",
    "    ToFloat, ShiftScaleRotate,GridDistortion, ElasticTransform, JpegCompression, HueSaturationValue,\n",
    "    RGBShift, RandomBrightness, RandomContrast, Blur, MotionBlur, MedianBlur, GaussNoise,CenterCrop,\n",
    "    IAAAdditiveGaussianNoise,GaussNoise,OpticalDistortion,RandomSizedCrop\n",
    ")\n",
    "\n",
    "AUGMENTATIONS_TRAIN = Compose([\n",
    "    HorizontalFlip(p=0.5),\n",
    "    OneOf([\n",
    "        RandomContrast(),\n",
    "        RandomGamma(),\n",
    "        RandomBrightness(),\n",
    "         ], p=0.3),\n",
    "    OneOf([\n",
    "        ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        GridDistortion(),\n",
    "        OpticalDistortion(distort_limit=2, shift_limit=0.5),\n",
    "        ], p=0.3),\n",
    "    RandomSizedCrop(min_max_height=(176, 256), height=img_height, width=img_width,p=0.25),\n",
    "    ToFloat(max_value=1)\n",
    "],p=1)\n",
    "\n",
    "\n",
    "AUGMENTATIONS_TEST = Compose([\n",
    "    ToFloat(max_value=1)\n",
    "],p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pixel_array(data, figsize=(10,10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(data, cmap=plt.cm.bone)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_pixel_array_overlay(data, label, figsize=(10,10)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(data, cmap=plt.cm.bone)\n",
    "    plt.imshow(label, alpha=.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = DataGenerator(data_frame=train_df, batch_size=4, shuffle=False)\n",
    "images, masks = a.__getitem__(0)\n",
    "for image in images.squeeze():\n",
    "    plot_pixel_array(image, (5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After augmentations\n",
    "b = DataGenerator(data_frame=train_df, batch_size=4, augmentations=AUGMENTATIONS_TRAIN, shuffle=False)\n",
    "images, masks = a.__getitem__(0)\n",
    "for image in images.squeeze():\n",
    "    plot_pixel_array(image, (5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader with Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Pretrained ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_resnet50(img_height=img_height, img_width=img_width, n_channels=n_channels):\n",
    "    inputs = Input(shape=(img_height, img_width, n_channels))\n",
    "    conc = Concatenate()([inputs, inputs, inputs])\n",
    "    \n",
    "    base = ResNet50(include_top=False, weights='imagenet', input_tensor = conc, classes=2)\n",
    "    \n",
    "    for layer in base.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    outputs = GlobalAveragePooling2D()(base.output)\n",
    "    outputs = Dense(2, activation='softmax')(outputs)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "def get_resnext50(img_height=img_height, img_width=img_width, n_channels=n_channels):\n",
    "    inputs = Input(shape=(img_height, img_width, n_channels))\n",
    "    conc = Concatenate()([inputs, inputs, inputs])\n",
    "    \n",
    "    base = ResNeXt50(include_top=False, weights='imagenet', input_tensor = conc, classes=2)\n",
    "    \n",
    "    for layer in base.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    outputs = GlobalAveragePooling2D()(base.output)\n",
    "    outputs = Dense(2, activation='softmax')(outputs)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = get_resnet50()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.00001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint('./save/resnet50_best.h5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(data_frame=train_df, img_height=img_height, img_width=img_width, batch_size=batch_size)\n",
    "validation_generator = DataGenerator(data_frame=val_df, img_height=img_height, img_width=img_width, batch_size=batch_size)\n",
    "history = model.fit_generator(generator=training_generator,\n",
    "                              validation_data=validation_generator,\n",
    "                              use_multiprocessing=False,\n",
    "                              epochs=epochs,\n",
    "                              verbose=1,\n",
    "                              callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./save/resnet50_final.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check on Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_generator = DataGenerator(data_frame=val_df, img_height=img_height, img_width=img_width, batch_size=batch_size, shuffle=False)\n",
    "preds_val = model.predict_generator(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.argmax(preds_val, axis=-1)\n",
    "z[0:10]\n",
    "p = np.argmax(val_df.)\n",
    "#acc = K.mean(K.equal(K.argmax(val_df.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_val[0]\n",
    "np.argmax(np.array(val_df[['Pneumothorax', 'NotPneumothorax']]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(np.equal(np.argmax(preds_val, axis=-1), np.argmax(np.array(val_df[['Pneumothorax', 'NotPneumothorax']]), axis=-1)))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['val_loss'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
